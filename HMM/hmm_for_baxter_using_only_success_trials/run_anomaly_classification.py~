
import sys
import os
import pandas as pd
import numpy as np
import shutil
import training_config
import generate_synthetic_data
import model_generation
import model_score
import util
import itertools
from sklearn.externals import joblib
from sklearn.model_selection import LeavePOut
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt


import ipdb
   
def predict_proba(x_test, class_names):
    # load trained anomaly models
    anomaly_model_group_by_label = {}
    for fo in class_names:
        anomaly_model_path = os.path.join(training_config.anomaly_model_save_path,
                                               fo,
                                               training_config.config_by_user['data_type_chosen'],
                                               training_config.config_by_user['model_type_chosen'],
                                               training_config.model_id)
        try:
            anomaly_model_group_by_label[fo] = joblib.load(anomaly_model_path + "/model_s%s.pkl"%(1,))
        except IOError:
            print 'anomaly model of  %s not found'%(fo,)
            raw_input("sorry! cann't load the anomaly model")
            continue

    predict_score = []
    for i in range(len(x_test)):
        temp_loglik = []
        for model_label in class_names:
            one_log_curve_of_this_model = util.fast_log_curve_calculation(x_test[i], anomaly_model_group_by_label[model_label])
            temp_loglik.append(one_log_curve_of_this_model[-1])
        temp_score = temp_loglik / np.sum(temp_loglik)
        predict_score.append(temp_score)
    return np.array(predict_score)

def predict(x_test, class_names):
    # load trained anomaly models
    anomaly_model_group_by_label = {}
    for fo in class_names:
        anomaly_model_path = os.path.join(training_config.anomaly_model_save_path,
                                               fo,
                                               training_config.config_by_user['data_type_chosen'],
                                               training_config.config_by_user['model_type_chosen'],
                                               training_config.model_id)
        try:
            anomaly_model_group_by_label[fo] = joblib.load(anomaly_model_path + "/model_s%s.pkl"%(1,))
        except IOError:
            print 'anomaly model of  %s not found'%(fo,)
            raw_input("sorry! cann't load the anomaly model")
            continue
    y_pred = []
    for i in range(len(x_test)):

        # plot
        # fig = plt.figure()
        # ax = fig.add_subplot(111)
        # from matplotlib.pyplot import cm
        # color = iter(cm.rainbow(np.linspace(0, 1, len(anomaly_model_group_by_label))))

        calc_cofidence_resourse = []
        for idx, model_label in enumerate(class_names):
            one_log_curve_of_this_model = util.fast_log_curve_calculation(x_test[i], 
                                                                        anomaly_model_group_by_label[model_label])
            calc_cofidence_resourse.append({
                'model_idx'         : idx,
                'model_label'       : model_label,
                'culmulative_loglik': one_log_curve_of_this_model[-1],
                })

        #     c = next(color)
        #     plot_line, = ax.plot(one_log_curve_of_this_model, linestyle="solid", color = c)
        #     plot_line.set_label(model_label)
        # title = ('Anomaly_identification for ' + fo)
        # ax.set_title(title)
        # plt.savefig('images/'+str(i) + '.png', dpi=120)

        sorted_list = sorted(calc_cofidence_resourse, key=lambda x:x['culmulative_loglik'])
        optimal_result = sorted_list[-1]
        classified_idx = optimal_result['model_idx']
        y_pred.append(classified_idx)

    return y_pred

def train_model(x_train, y_train, class_names):
    '''
    function: train all the anomalious models
    '''
    for idx, model_name in enumerate(class_names):
        indices = [i for i, label in enumerate(y_train) if label == idx]
        train_data = x_train[indices] 
        model_list, lengths = [], []
        for i in range(len(train_data)):
            lengths.append(train_data[i].shape[0])
        try:
            train_data = np.concatenate(train_data, axis=0)
        except ValueError:
            print ('Oops!. something wrong...')
            sys.exit()
        lengths[-1] -=1
        model_generator = model_generation.get_model_generator(training_config.model_type_chosen, training_config.model_config)
        for model, now_model_config in model_generator:
            model = model.fit(train_data, lengths=lengths)  # n_samples, n_features
            score = model_score.score(training_config.score_metric, model, train_data, lengths)
            if score == None:
                print "scorer says to skip this model, will do"
                continue
            model_list.append({
                "model": model,
                "now_model_config": now_model_config,
                "score": score
            })
            print 'score:', score
            model_generation.update_now_score(score)        
        sorted_model_list = sorted(model_list, key=lambda x:x['score'])

        best = sorted_model_list[0]
        model_id = util.get_model_config_id(best['now_model_config'])

        anomaly_model_path = os.path.join(training_config.anomaly_model_save_path, 
                                                   model_name, 
                                                   training_config.config_by_user['data_type_chosen'], 
                                                   training_config.config_by_user['model_type_chosen'], 
                                                   training_config.model_id)
        
        if not os.path.isdir(anomaly_model_path):
            os.makedirs(anomaly_model_path)
            
        joblib.dump(
            best['model'],
            os.path.join(anomaly_model_path, "model_s%s.pkl"%(1,))
        )

def run():

    # load the train/test/labels file
    TRAIN_TEST_DATASET_PATH = training_config.anomaly_data_path
    x_train_path = os.path.join(TRAIN_TEST_DATASET_PATH, "X_train.npy")
    y_train_path = os.path.join(TRAIN_TEST_DATASET_PATH, "y_train.npy")
    x_test_path  = os.path.join(TRAIN_TEST_DATASET_PATH,  "X_test.npy")
    y_test_path  = os.path.join(TRAIN_TEST_DATASET_PATH,  "y_test.npy")
    labels_path  = os.path.join(TRAIN_TEST_DATASET_PATH,  "labels_list.npy")

    try:
        x_train = np.load(x_train_path)
        y_train = np.load(y_train_path)
        x_test  = np.load(x_test_path)
        y_test  = np.load(y_test_path)
        labels  = np.load(labels_path)
    except IOError:
        print ('Error occured trying to read the file, please check the path: ' + TRAIN_TEST_DATASET_PATH)
        sys.exit()

    y_train =  y_train.reshape(-1,).tolist()
    y_test  =  y_test.reshape(-1,).tolist()
    class_names = labels.tolist()

    train_model(x_train, y_train, class_names)

    from evaluate_metrics import (plot_confusion_matrix, plot_roc_for_multiple_classes, \
                                      plot_precision_recall)

    # for confusion matrix
    y_pred = predict(x_test, class_names)
    plot_confusion_matrix.run( y_test, y_pred, class_names)
    
    # for plot roc
    y_score = predict_proba(x_test, class_names)
    plot_roc_for_multiple_classes.run(y_score, y_test, class_names)

    # for plot precision-recall curve
    plot_precision_recall.run(y_score, y_test, class_names)

    
    plt.show() 

if __name__=='__main__':
    sys.exit(run())
 
